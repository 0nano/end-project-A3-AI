{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Apprentissage Supervis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeur cible 1 :  id_code_insee  -  8258\n",
      "Valeur cible 2 :  Num_Acc  -  40250\n",
      "Valeur cible 3 :  num_veh  -  58\n",
      "Valeur cible 4 :  id_usa  -  73643\n",
      "Valeur cible 5 :  date  -  29950\n",
      "Valeur cible 6 :  ville  -  8078\n",
      "Valeur cible 7 :  latitude.x  -  1253\n",
      "Valeur cible 8 :  longitude.x  -  1495\n",
      "Valeur cible 9 :  descr_cat_veh  -  24\n",
      "Valeur cible 10 :  descr_agglo  -  2\n",
      "Valeur cible 11 :  descr_athmo  -  9\n",
      "Valeur cible 12 :  descr_lum  -  5\n",
      "Valeur cible 13 :  descr_etat_surf  -  9\n",
      "Valeur cible 14 :  description_intersection  -  9\n",
      "Valeur cible 15 :  an_nais  -  101\n",
      "Valeur cible 16 :  age  -  101\n",
      "Valeur cible 17 :  place  -  10\n",
      "Valeur cible 18 :  descr_dispo_secu  -  15\n",
      "Valeur cible 19 :  descr_grav  -  4\n",
      "Valeur cible 20 :  descr_motif_traj  -  6\n",
      "Valeur cible 21 :  descr_type_col  -  7\n",
      "Valeur cible 22 :  department_name  -  89\n",
      "Valeur cible 23 :  department_number  -  89\n",
      "Valeur cible 24 :  region_name  -  17\n",
      "Nombre d'instances :  73643\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des features :  23\n",
      "  id_code_insee       Num_Acc num_veh  id_usa            date  \\\n",
      "0         10100  200900035904     A01  823507  20090803130000   \n",
      "1         10100  200900004313     A01  752937  20090227223000   \n",
      "2         10102  200900005197     A01  754945  20090113160000   \n",
      "3         10102  200900005197     B02  754947  20090113160000   \n",
      "4         10102  200900005206     A01  754970  20090209201500   \n",
      "\n",
      "              ville  latitude.x  longitude.x  descr_cat_veh  descr_agglo  ...  \\\n",
      "0            CLEREY     48.2000          4.2              2            1  ...   \n",
      "1            CLEREY     48.2000          4.2              3            2  ...   \n",
      "2  COLOMBE LA FOSSE     48.2667          4.8              3            2  ...   \n",
      "3  COLOMBE LA FOSSE     48.2667          4.8              3            2  ...   \n",
      "4  COLOMBE LA FOSSE     48.2667          4.8              6            2  ...   \n",
      "\n",
      "   an_nais   age  place                         descr_dispo_secu  descr_grav  \\\n",
      "0   1952.0  57.0    1.0  Utilisation d'une ceinture de s√©curit√©            0   \n",
      "1   1952.0  57.0    1.0  Utilisation d'une ceinture de s√©curit√©            2   \n",
      "2   1969.0  40.0    1.0  Utilisation d'une ceinture de s√©curit√©            2   \n",
      "3   1939.0  70.0    1.0  Utilisation d'une ceinture de s√©curit√©            0   \n",
      "4   1966.0  43.0    1.0                 Utilisation d'un casque            1   \n",
      "\n",
      "   descr_motif_traj                descr_type_col department_name  \\\n",
      "0                 1               Autre collision            aube   \n",
      "1                 9     Deux v√©hicules - Frontale            aube   \n",
      "2                 5  Deux v√©hicules ‚Äì Par le cot√©            aube   \n",
      "3                 5  Deux v√©hicules ‚Äì Par le cot√©            aube   \n",
      "4                 1                Sans collision            aube   \n",
      "\n",
      "   department_number  region_name  \n",
      "0                 10    grand est  \n",
      "1                 10    grand est  \n",
      "2                 10    grand est  \n",
      "3                 10    grand est  \n",
      "4                 10    grand est  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "cc\n"
     ]
    }
   ],
   "source": [
    "%run preparation.ipynb\n",
    "data = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73643 entries, 0 to 73642\n",
      "Data columns (total 21 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id_code_insee             73643 non-null  int32  \n",
      " 1   Num_Acc                   73643 non-null  int64  \n",
      " 2   id_usa                    73643 non-null  int64  \n",
      " 3   date                      73643 non-null  Int64  \n",
      " 4   latitude.x                73643 non-null  float64\n",
      " 5   longitude.x               73643 non-null  float64\n",
      " 6   descr_cat_veh             73643 non-null  int64  \n",
      " 7   descr_agglo               73643 non-null  int64  \n",
      " 8   descr_athmo               73643 non-null  int64  \n",
      " 9   descr_lum                 73643 non-null  int64  \n",
      " 10  descr_etat_surf           73643 non-null  int64  \n",
      " 11  description_intersection  73643 non-null  int64  \n",
      " 12  an_nais                   73643 non-null  float64\n",
      " 13  age                       73643 non-null  float64\n",
      " 14  place                     73643 non-null  float64\n",
      " 15  descr_dispo_secu          73643 non-null  int64  \n",
      " 16  descr_grav                73643 non-null  int64  \n",
      " 17  descr_motif_traj          73643 non-null  int64  \n",
      " 18  descr_type_col            73643 non-null  int64  \n",
      " 19  department_number         73643 non-null  int32  \n",
      " 20  region_number             73643 non-null  int32  \n",
      "dtypes: Int64(1), float64(5), int32(3), int64(12)\n",
      "memory usage: 11.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73643 entries, 0 to 73642\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   descr_cat_veh     73643 non-null  int64  \n",
      " 1   descr_agglo       73643 non-null  int64  \n",
      " 2   descr_athmo       73643 non-null  int64  \n",
      " 3   descr_lum         73643 non-null  int64  \n",
      " 4   descr_etat_surf   73643 non-null  int64  \n",
      " 5   age               73643 non-null  float64\n",
      " 6   descr_dispo_secu  73643 non-null  int64  \n",
      " 7   descr_grav        73643 non-null  int64  \n",
      " 8   descr_type_col    73643 non-null  int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 5.1 MB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(\"id_code_insee\", axis='columns')\n",
    "data = data.drop(\"Num_Acc\", axis='columns')\n",
    "data = data.drop(\"id_usa\", axis='columns')\n",
    "data = data.drop(\"date\", axis='columns')\n",
    "data = data.drop(\"latitude.x\", axis='columns')\n",
    "data = data.drop(\"longitude.x\", axis='columns')\n",
    "data = data.drop(\"an_nais\", axis='columns')\n",
    "data = data.drop(\"description_intersection\", axis='columns')\n",
    "data = data.drop(\"descr_motif_traj\", axis='columns')\n",
    "data = data.drop(\"department_number\", axis='columns')\n",
    "data = data.drop(\"region_number\", axis='columns')\n",
    "data = data.drop(\"place\", axis='columns')\n",
    "#Copie de la table initiale Data afin de la garder intacte pour des tests ulterieurs\n",
    "copy_data = data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descr_cat_veh</th>\n",
       "      <th>descr_agglo</th>\n",
       "      <th>descr_athmo</th>\n",
       "      <th>descr_lum</th>\n",
       "      <th>descr_etat_surf</th>\n",
       "      <th>age</th>\n",
       "      <th>descr_dispo_secu</th>\n",
       "      <th>descr_grav</th>\n",
       "      <th>descr_type_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   descr_cat_veh  descr_agglo  descr_athmo  descr_lum  descr_etat_surf   age  \\\n",
       "0              2            1            4          2                4  57.0   \n",
       "1              3            2            4          3                4  57.0   \n",
       "2              3            2            5          2                4  40.0   \n",
       "3              3            2            5          2                4  70.0   \n",
       "4              6            2            6          1                3  43.0   \n",
       "\n",
       "   descr_dispo_secu  descr_grav  descr_type_col  \n",
       "0                 0           0               0  \n",
       "1                 0           2               1  \n",
       "2                 0           2               2  \n",
       "3                 0           0               2  \n",
       "4                 1           1               3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Importation des librairies\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data =pandas.read_csv(\"export_IA.csv\", sep=\",\")\n",
    "\n",
    "#data.info()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 2944 entries, 30308 to 65689\n",
      "Series name: descr_grav\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "2944 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 46.0 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pandas\n",
    "#CREATION D\"UN ECHANTILLOn AFIN DE REALISER DES TESTS DE GRIDSEARCH\n",
    "sample = data\n",
    "#sample.info()\n",
    "count1 = sum(sample['descr_grav'] == 0)\n",
    "count2 = sum(sample['descr_grav'] == 1)\n",
    "count3 = sum(sample['descr_grav'] == 2)\n",
    "count4 = sum(sample['descr_grav'] == 3)\n",
    "#print(count1,count2,count3,count4, count1+count2+count3+count4)\n",
    "\n",
    "#Choix du pourcentage de l'√©chantillon par rapport a la tabe initiale: ici 4% (0.04)\n",
    "sample_size = 0.04\n",
    "sample1 = sample.query('descr_grav == 0').sample(n=int(count1 * sample_size), random_state=25)\n",
    "sample2 = sample.query('descr_grav == 1').sample(n=int(count2 * sample_size), random_state=25)\n",
    "sample3 = sample.query('descr_grav == 2').sample(n=int(count3 * sample_size), random_state=25)\n",
    "sample4 = sample.query('descr_grav == 3').sample(n=int(count4 * sample_size), random_state=25)\n",
    "final_sample = pandas.concat([sample1, sample2, sample3, sample4])\n",
    "#final_sample.info()\n",
    "sample_target = final_sample.pop('descr_grav')\n",
    "sample_target.info()\n",
    "X_train_sample, X_test_sample,y_train_sample, y_test_sample = train_test_split(final_sample,sample_target, test_size=0.2, random_state=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Recuperation de la valeur qui va nous servir de targer: la gravit√© de l'accident\n",
    "target = data.pop(\"descr_grav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Librairies utiles aux 3 classifications:\n",
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "#RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de donn√©  1\n",
      "Accuracy SVM: 0.5583542670921312\n",
      "Accuracy RF: 0.5656188471722452\n",
      "Accuracy MLP: 0.5950166338515853\n",
      "\n",
      "Jeu de donn√©  2\n",
      "Accuracy SVM: 0.5416525222350465\n",
      "Accuracy RF: 0.5593726661687827\n",
      "Accuracy MLP: 0.5844252834544097\n",
      "\n",
      "Jeu de donn√©  3\n",
      "Accuracy SVM: 0.5518365130015616\n",
      "Accuracy RF: 0.5605947450607645\n",
      "Accuracy MLP: 0.6026206802905832\n",
      "\n",
      "Jeu de donn√©  4\n",
      "Accuracy SVM: 0.5412451626043859\n",
      "Accuracy RF: 0.5603231719736574\n",
      "Accuracy MLP: 0.5931835155136126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de donn√©  5\n",
      "Accuracy SVM: 0.5466087310747505\n",
      "Accuracy RF: 0.5593047728970059\n",
      "Accuracy MLP: 0.5929119424265056\n",
      "\n",
      "Moyenne SVM: 0.5479394392015752\n",
      "Moyenne RF: 0.5610428406544912\n",
      "Moyenne MLP: 0.5936316111073393\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "#Creation de vecteurs afin de stocker les scores de chaque jeu de donn√©es\n",
    "average_SVM = []\n",
    "average_RF = []\n",
    "average_MLP = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(data,target, test_size=0.2, random_state=i*10)\n",
    "    svm.fit(X_train, y_train)\n",
    "    rf.fit(X_train, y_train)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred_svm = svm.predict(X_test)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    y_pred_mlp = mlp.predict(X_test)\n",
    "    print(\"Jeu de donn√© \", i+1)\n",
    "    score_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    score_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    score_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "    print(\"Accuracy SVM:\", score_svm)\n",
    "    average_SVM.append(score_svm)\n",
    "    average_RF.append(score_rf)\n",
    "    average_MLP.append(score_mlp)\n",
    "    print(\"Accuracy RF:\", score_rf)\n",
    "    print(\"Accuracy MLP:\", score_mlp)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "print(\"Moyenne SVM:\", np.mean(average_SVM))\n",
    "print(\"Moyenne RF:\", np.mean(average_RF))\n",
    "print(\"Moyenne MLP:\", np.mean(average_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Leave one out\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(data)\n",
    "for train_index, test_index in loo.split(data):\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de donn√© a partir du Leave One Out :\n",
      "Accuracy SVM: 1.0\n",
      "Accuracy RF: 1.0\n",
      "Accuracy MLP: 1.0\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "mlp = MLPClassifier()\n",
    " \n",
    "svm.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "print(\"Jeu de donn√© a partir du Leave One Out :\")\n",
    "score_svm = accuracy_score(y_test, y_pred_svm)\n",
    "score_rf = accuracy_score(y_test, y_pred_rf)\n",
    "score_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Accuracy SVM:\", score_svm)\n",
    "print(\"Accuracy RF:\", score_rf)\n",
    "print(\"Accuracy MLP:\", score_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From scratch\n",
    "\n",
    "#On melange les donnees de copy_data\n",
    "copy_data = copy_data.sample(frac=1)\n",
    "\n",
    "#On recupere le nombre de lignes de copy_data afin de savoir combien de lignes on va mettre dans le train set et dans le test set pour 80% de train et 20% de test\n",
    "total_rows = len(copy_data)\n",
    "train_size = int(total_rows*0.8)\n",
    "\n",
    "#Separation des donnees entre train et test\n",
    "X_train = copy_data[0:train_size]\n",
    "X_test = copy_data[train_size:]\n",
    "\n",
    "#Separation des donnees entre X et y\n",
    "y_train = X_train.pop('descr_grav')\n",
    "y_test = X_test.pop('descr_grav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de donn√© from Scratch :\n",
      "Accuracy SVM: 0.5477629166949556\n",
      "Accuracy RF: 0.5650078077262544\n",
      "Accuracy MLP: 0.5900604250118813\n"
     ]
    }
   ],
   "source": [
    "#Test de l'algorithm from scratch\n",
    "svm = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "mlp = MLPClassifier()\n",
    " \n",
    "svm.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "print(\"Jeu de donn√© from Scratch :\")\n",
    "score_svm = accuracy_score(y_test, y_pred_svm)\n",
    "score_rf = accuracy_score(y_test, y_pred_rf)\n",
    "score_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Accuracy SVM:\", score_svm)\n",
    "print(\"Accuracy RF:\", score_rf)\n",
    "print(\"Accuracy MLP:\", score_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleures parametres SVM: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Meilleur estimateur:  SVC(C=10)\n",
      "SVM Accuracy: 0.5449915110356537\n",
      "Precision: 0.5070794374471712\n",
      "Recall: 0.5449915110356537\n",
      "F1 Score: 0.4761175146157662\n",
      "Matrice de confusion :\n",
      " [[204  31   1   0]\n",
      " [104 114   1   0]\n",
      " [ 55  59   3   0]\n",
      " [ 10   5   2   0]]\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0       0.123796      0.007306         0.066400        0.003440     0.1   \n",
      "1       0.147599      0.011160         0.068401        0.001952     0.1   \n",
      "2       0.131794      0.004925         0.065200        0.003310       1   \n",
      "3       0.153598      0.003506         0.063608        0.001197       1   \n",
      "4       0.150010      0.002818         0.058397        0.000800      10   \n",
      "5       0.208605      0.009769         0.062793        0.001725      10   \n",
      "\n",
      "  param_gamma param_kernel                                         params  \\\n",
      "0       scale          rbf  {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
      "1        auto          rbf   {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}   \n",
      "2       scale          rbf    {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
      "3        auto          rbf     {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}   \n",
      "4       scale          rbf   {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
      "5        auto          rbf    {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}   \n",
      "\n",
      "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0           0.503185           0.515924           0.518047           0.530786   \n",
      "1           0.475584           0.479830           0.490446           0.488323   \n",
      "2           0.509554           0.524416           0.520170           0.530786   \n",
      "3           0.549894           0.558386           0.552017           0.543524   \n",
      "4           0.545648           0.560510           0.569002           0.549894   \n",
      "5           0.532909           0.507431           0.520170           0.526539   \n",
      "\n",
      "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0           0.520170         0.517622        0.008846                5  \n",
      "1           0.486200         0.484076        0.005536                6  \n",
      "2           0.528662         0.522718        0.007524                4  \n",
      "3           0.562633         0.553291        0.006660                2  \n",
      "4           0.560510         0.557113        0.008343                1  \n",
      "5           0.528662         0.523142        0.008867                3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Definition de la grille pour le  GridSearch\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Creation de l'instance de classification SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Creation du GridSearch avec le SVM et le param_grid\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm)\n",
    "\n",
    "# Entrainement du modele\n",
    "grid_search_svm.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "\n",
    "# Recuperation du meilleur parametre et de l'estimateur\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_model_svm = grid_search_svm.best_estimator_\n",
    "joblib.dump(best_model_svm, 'best_model_svm.pkl')#Souvegarde du modele\n",
    "loaded_model_svm = joblib.load('best_model_svm.pkl') #Chargement du modele enregistre\n",
    "# Prediction sur le modele\n",
    "y_pred_svm = loaded_model_svm.predict(X_test_sample)\n",
    "\n",
    "# Evaluation des performances du modele\n",
    "print(\"Meilleures parametres SVM:\", best_params_svm)\n",
    "print(\"Meilleur estimateur: \", best_model_svm)\n",
    "accuracy_svm = accuracy_score(y_test_sample, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n",
    "precision = precision_score(y_test_sample, y_pred_svm, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test_sample, y_pred_svm, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test_sample, y_pred_svm, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n",
    "confusion_mat = confusion_matrix(y_test_sample, y_pred_svm)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n",
    "results = grid_search_svm.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseSVC.predict() takes 2 positional arguments but 9 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m loaded_model_svm\u001b[39m.\u001b[39;49mpredict(\u001b[39m2\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m4\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m4\u001b[39;49m,\u001b[39m57.0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "\u001b[1;31mTypeError\u001b[0m: BaseSVC.predict() takes 2 positional arguments but 9 were given"
     ]
    }
   ],
   "source": [
    "result = loaded_model_svm.predict(2,1,4,2,4,57.0,0,0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleures parametres RF: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "Random Forest Accuracy: 0.601018675721562\n",
      "Precision: 0.5744647411134692\n",
      "Recall: 0.601018675721562\n",
      "F1 Score: 0.5751419026489958\n",
      "Matrice de confusion :\n",
      " [[203  21  12   0]\n",
      " [ 83 113  23   0]\n",
      " [ 35  44  38   0]\n",
      " [  7   3   7   0]]\n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.288003      0.011884         0.016804        0.000755   \n",
      "1        0.551795      0.011473         0.032405        0.002239   \n",
      "2        1.405382      0.037318         0.076677        0.003012   \n",
      "3        0.232923      0.008128         0.015979        0.000633   \n",
      "4        0.472222      0.012092         0.028857        0.001285   \n",
      "5        1.181350      0.017630         0.072835        0.002720   \n",
      "6        0.207160      0.007785         0.014999        0.001092   \n",
      "7        0.421300      0.022515         0.029039        0.001651   \n",
      "8        1.007578      0.006443         0.065709        0.001113   \n",
      "9        0.131591      0.001421         0.010603        0.000494   \n",
      "10       0.262310      0.003345         0.019808        0.000388   \n",
      "11       0.657201      0.009237         0.047407        0.002345   \n",
      "12       0.148591      0.014099         0.011802        0.000977   \n",
      "13       0.271953      0.010854         0.020402        0.000804   \n",
      "14       0.672660      0.019132         0.047442        0.001001   \n",
      "15       0.138990      0.010917         0.011803        0.001164   \n",
      "16       0.270399      0.008790         0.020402        0.001020   \n",
      "17       0.678786      0.013411         0.048220        0.001173   \n",
      "18       0.178000      0.005010         0.013397        0.000494   \n",
      "19       0.361394      0.004793         0.024999        0.000895   \n",
      "20       0.889406      0.013831         0.059193        0.002320   \n",
      "21       0.172814      0.004660         0.013195        0.000403   \n",
      "22       0.338393      0.005906         0.024207        0.000412   \n",
      "23       0.846001      0.006415         0.059392        0.002062   \n",
      "24       0.168197      0.003864         0.012803        0.000403   \n",
      "25       0.336397      0.004072         0.024208        0.000745   \n",
      "26       0.842652      0.025006         0.058192        0.001734   \n",
      "\n",
      "   param_max_depth param_min_samples_split param_n_estimators  \\\n",
      "0             None                       2                100   \n",
      "1             None                       2                200   \n",
      "2             None                       2                500   \n",
      "3             None                       5                100   \n",
      "4             None                       5                200   \n",
      "5             None                       5                500   \n",
      "6             None                      10                100   \n",
      "7             None                      10                200   \n",
      "8             None                      10                500   \n",
      "9                5                       2                100   \n",
      "10               5                       2                200   \n",
      "11               5                       2                500   \n",
      "12               5                       5                100   \n",
      "13               5                       5                200   \n",
      "14               5                       5                500   \n",
      "15               5                      10                100   \n",
      "16               5                      10                200   \n",
      "17               5                      10                500   \n",
      "18              10                       2                100   \n",
      "19              10                       2                200   \n",
      "20              10                       2                500   \n",
      "21              10                       5                100   \n",
      "22              10                       5                200   \n",
      "23              10                       5                500   \n",
      "24              10                      10                100   \n",
      "25              10                      10                200   \n",
      "26              10                      10                500   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'max_depth': None, 'min_samples_split': 2, 'n...           0.562633   \n",
      "1   {'max_depth': None, 'min_samples_split': 2, 'n...           0.558386   \n",
      "2   {'max_depth': None, 'min_samples_split': 2, 'n...           0.558386   \n",
      "3   {'max_depth': None, 'min_samples_split': 5, 'n...           0.558386   \n",
      "4   {'max_depth': None, 'min_samples_split': 5, 'n...           0.562633   \n",
      "5   {'max_depth': None, 'min_samples_split': 5, 'n...           0.571125   \n",
      "6   {'max_depth': None, 'min_samples_split': 10, '...           0.573248   \n",
      "7   {'max_depth': None, 'min_samples_split': 10, '...           0.573248   \n",
      "8   {'max_depth': None, 'min_samples_split': 10, '...           0.592357   \n",
      "9   {'max_depth': 5, 'min_samples_split': 2, 'n_es...           0.575372   \n",
      "10  {'max_depth': 5, 'min_samples_split': 2, 'n_es...           0.583864   \n",
      "11  {'max_depth': 5, 'min_samples_split': 2, 'n_es...           0.588110   \n",
      "12  {'max_depth': 5, 'min_samples_split': 5, 'n_es...           0.588110   \n",
      "13  {'max_depth': 5, 'min_samples_split': 5, 'n_es...           0.577495   \n",
      "14  {'max_depth': 5, 'min_samples_split': 5, 'n_es...           0.588110   \n",
      "15  {'max_depth': 5, 'min_samples_split': 10, 'n_e...           0.590234   \n",
      "16  {'max_depth': 5, 'min_samples_split': 10, 'n_e...           0.590234   \n",
      "17  {'max_depth': 5, 'min_samples_split': 10, 'n_e...           0.590234   \n",
      "18  {'max_depth': 10, 'min_samples_split': 2, 'n_e...           0.600849   \n",
      "19  {'max_depth': 10, 'min_samples_split': 2, 'n_e...           0.605096   \n",
      "20  {'max_depth': 10, 'min_samples_split': 2, 'n_e...           0.607219   \n",
      "21  {'max_depth': 10, 'min_samples_split': 5, 'n_e...           0.581741   \n",
      "22  {'max_depth': 10, 'min_samples_split': 5, 'n_e...           0.607219   \n",
      "23  {'max_depth': 10, 'min_samples_split': 5, 'n_e...           0.607219   \n",
      "24  {'max_depth': 10, 'min_samples_split': 10, 'n_...           0.611465   \n",
      "25  {'max_depth': 10, 'min_samples_split': 10, 'n_...           0.598726   \n",
      "26  {'max_depth': 10, 'min_samples_split': 10, 'n_...           0.602972   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.530786           0.535032           0.539278   \n",
      "1            0.543524           0.528662           0.545648   \n",
      "2            0.539278           0.526539           0.558386   \n",
      "3            0.571125           0.560510           0.562633   \n",
      "4            0.569002           0.556263           0.564756   \n",
      "5            0.575372           0.556263           0.564756   \n",
      "6            0.596603           0.575372           0.581741   \n",
      "7            0.592357           0.577495           0.585987   \n",
      "8            0.592357           0.581741           0.583864   \n",
      "9            0.588110           0.605096           0.583864   \n",
      "10           0.583864           0.596603           0.581741   \n",
      "11           0.590234           0.602972           0.579618   \n",
      "12           0.579618           0.598726           0.579618   \n",
      "13           0.585987           0.600849           0.581741   \n",
      "14           0.590234           0.600849           0.581741   \n",
      "15           0.583864           0.598726           0.579618   \n",
      "16           0.590234           0.607219           0.583864   \n",
      "17           0.585987           0.605096           0.579618   \n",
      "18           0.602972           0.585987           0.585987   \n",
      "19           0.611465           0.596603           0.585987   \n",
      "20           0.605096           0.592357           0.585987   \n",
      "21           0.600849           0.605096           0.592357   \n",
      "22           0.596603           0.600849           0.596603   \n",
      "23           0.607219           0.588110           0.583864   \n",
      "24           0.607219           0.596603           0.594480   \n",
      "25           0.605096           0.613588           0.588110   \n",
      "26           0.607219           0.602972           0.596603   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.554140         0.544374        0.012055               27  \n",
      "1            0.560510         0.547346        0.011504               26  \n",
      "2            0.562633         0.549045        0.013864               25  \n",
      "3            0.558386         0.562208        0.004728               24  \n",
      "4            0.571125         0.564756        0.005201               23  \n",
      "5            0.569002         0.567304        0.006496               22  \n",
      "6            0.585987         0.582590        0.008343               21  \n",
      "7            0.594480         0.584713        0.008234               20  \n",
      "8            0.588110         0.587686        0.004330               18  \n",
      "9            0.594480         0.589384        0.010013               14  \n",
      "10           0.596603         0.588535        0.006633               16  \n",
      "11           0.598726         0.591932        0.008212               11  \n",
      "12           0.590234         0.587261        0.007181               19  \n",
      "13           0.596603         0.588535        0.008846               16  \n",
      "14           0.594480         0.591083        0.006384               13  \n",
      "15           0.592357         0.588960        0.006660               15  \n",
      "16           0.598726         0.594055        0.008101               10  \n",
      "17           0.598726         0.591932        0.009048               11  \n",
      "18           0.596603         0.594480        0.007231                9  \n",
      "19           0.596603         0.599151        0.008640                5  \n",
      "20           0.600849         0.598301        0.007989                6  \n",
      "21           0.600849         0.596178        0.008321                8  \n",
      "22           0.600849         0.600425        0.003892                2  \n",
      "23           0.605096         0.598301        0.010173                6  \n",
      "24           0.590234         0.600000        0.008012                4  \n",
      "25           0.594480         0.600000        0.008764                3  \n",
      "26           0.598726         0.601699        0.003702                1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "#from sklearn.externals import joblib\n",
    "\n",
    "# Definition des parametre de grille pour le GridSearch\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Creation de l'instance de classification Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Creation du GridSearch avec le RF et les parametres a tester\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf)\n",
    "\n",
    "# Entrainement du modele\n",
    "grid_search_rf.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Recuperation des meilleurs parametres et de l'estimateur\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "joblib.dump(best_model_rf, 'best_model_rf.pkl')#Souvegarde du modele\n",
    "loaded_model_rf = joblib.load('best_model_rf.pkl') #Chargement du modele enregistre\n",
    "# Prediction sur le modele\n",
    "y_pred_rf = loaded_model_rf.predict(X_test_sample)\n",
    "\n",
    "\n",
    "# Evaluation des performances du modele\n",
    "print(\"Meilleures parametres RF:\", best_params_rf)\n",
    "accuracy_rf = accuracy_score(y_test_sample, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
    "precision = precision_score(y_test_sample, y_pred_rf, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test_sample, y_pred_rf, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test_sample, y_pred_rf, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n",
    "confusion_mat = confusion_matrix(y_test_sample, y_pred_rf)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n",
    "results = grid_search_rf.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleures parametres MLP: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (200, 100)}\n",
      "MLP Accuracy: 0.5959252971137521\n",
      "Precision: 0.5803250533075373\n",
      "Recall: 0.5959252971137521\n",
      "F1 Score: 0.5701142258640269\n",
      "Matrice de confusion :\n",
      " [[198  26  12   0]\n",
      " [ 83 120  15   1]\n",
      " [ 33  51  32   1]\n",
      " [  9   5   2   1]]\n",
      "Resultats en matrice \n",
      "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.697175      0.142880         0.002406        0.000499   \n",
      "1        1.744775      0.625020         0.002603        0.000799   \n",
      "2        2.506425      0.743312         0.002397        0.000492   \n",
      "3        0.848412      0.145941         0.001985        0.000017   \n",
      "4        1.616800      0.339351         0.002594        0.000497   \n",
      "5        2.775401      1.263517         0.002801        0.000399   \n",
      "6        0.843057      0.239801         0.002212        0.000405   \n",
      "7        2.067837      0.561719         0.002600        0.000489   \n",
      "8        2.436997      0.736881         0.002801        0.000748   \n",
      "9        0.992994      0.184047         0.002399        0.000517   \n",
      "10       2.994456      0.104592         0.002401        0.000799   \n",
      "11       4.943217      0.174732         0.003600        0.000489   \n",
      "12       1.071719      0.063761         0.002190        0.000404   \n",
      "13       2.683246      0.610937         0.002801        0.000400   \n",
      "14       5.208656      0.426801         0.003601        0.000803   \n",
      "15       1.066003      0.064039         0.002184        0.000417   \n",
      "16       2.629330      0.598328         0.002399        0.000490   \n",
      "17       4.905500      0.024196         0.003200        0.000400   \n",
      "\n",
      "   param_activation param_alpha param_hidden_layer_sizes  \\\n",
      "0              relu      0.0001                   (100,)   \n",
      "1              relu      0.0001                (100, 50)   \n",
      "2              relu      0.0001               (200, 100)   \n",
      "3              relu       0.001                   (100,)   \n",
      "4              relu       0.001                (100, 50)   \n",
      "5              relu       0.001               (200, 100)   \n",
      "6              relu        0.01                   (100,)   \n",
      "7              relu        0.01                (100, 50)   \n",
      "8              relu        0.01               (200, 100)   \n",
      "9              tanh      0.0001                   (100,)   \n",
      "10             tanh      0.0001                (100, 50)   \n",
      "11             tanh      0.0001               (200, 100)   \n",
      "12             tanh       0.001                   (100,)   \n",
      "13             tanh       0.001                (100, 50)   \n",
      "14             tanh       0.001               (200, 100)   \n",
      "15             tanh        0.01                   (100,)   \n",
      "16             tanh        0.01                (100, 50)   \n",
      "17             tanh        0.01               (200, 100)   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'activation': 'relu', 'alpha': 0.0001, 'hidde...           0.569002   \n",
      "1   {'activation': 'relu', 'alpha': 0.0001, 'hidde...           0.573248   \n",
      "2   {'activation': 'relu', 'alpha': 0.0001, 'hidde...           0.573248   \n",
      "3   {'activation': 'relu', 'alpha': 0.001, 'hidden...           0.573248   \n",
      "4   {'activation': 'relu', 'alpha': 0.001, 'hidden...           0.571125   \n",
      "5   {'activation': 'relu', 'alpha': 0.001, 'hidden...           0.571125   \n",
      "6   {'activation': 'relu', 'alpha': 0.01, 'hidden_...           0.558386   \n",
      "7   {'activation': 'relu', 'alpha': 0.01, 'hidden_...           0.575372   \n",
      "8   {'activation': 'relu', 'alpha': 0.01, 'hidden_...           0.577495   \n",
      "9   {'activation': 'tanh', 'alpha': 0.0001, 'hidde...           0.583864   \n",
      "10  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...           0.569002   \n",
      "11  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...           0.560510   \n",
      "12  {'activation': 'tanh', 'alpha': 0.001, 'hidden...           0.581741   \n",
      "13  {'activation': 'tanh', 'alpha': 0.001, 'hidden...           0.554140   \n",
      "14  {'activation': 'tanh', 'alpha': 0.001, 'hidden...           0.577495   \n",
      "15  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...           0.596603   \n",
      "16  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...           0.588110   \n",
      "17  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...           0.558386   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.575372           0.592357           0.583864   \n",
      "1            0.562633           0.583864           0.575372   \n",
      "2            0.571125           0.588110           0.571125   \n",
      "3            0.581741           0.613588           0.590234   \n",
      "4            0.562633           0.605096           0.581741   \n",
      "5            0.569002           0.590234           0.571125   \n",
      "6            0.602972           0.598726           0.562633   \n",
      "7            0.552017           0.592357           0.566879   \n",
      "8            0.579618           0.588110           0.547771   \n",
      "9            0.575372           0.605096           0.583864   \n",
      "10           0.566879           0.598726           0.577495   \n",
      "11           0.596603           0.607219           0.594480   \n",
      "12           0.566879           0.605096           0.596603   \n",
      "13           0.573248           0.590234           0.583864   \n",
      "14           0.592357           0.590234           0.590234   \n",
      "15           0.573248           0.609342           0.583864   \n",
      "16           0.590234           0.596603           0.581741   \n",
      "17           0.556263           0.585987           0.558386   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.571125         0.578344        0.008661                9  \n",
      "1            0.583864         0.575796        0.007876               12  \n",
      "2            0.549894         0.570701        0.012189               14  \n",
      "3            0.575372         0.586837        0.014624                5  \n",
      "4            0.583864         0.580892        0.014312                8  \n",
      "5            0.547771         0.569851        0.013468               15  \n",
      "6            0.566879         0.577919        0.018961               10  \n",
      "7            0.552017         0.567728        0.015228               16  \n",
      "8            0.505308         0.559660        0.030402               18  \n",
      "9            0.585987         0.586837        0.009831                5  \n",
      "10           0.575372         0.577495        0.011315               11  \n",
      "11           0.594480         0.590658        0.015797                1  \n",
      "12           0.585987         0.587261        0.013060                3  \n",
      "13           0.571125         0.574522        0.012351               13  \n",
      "14           0.575372         0.585138        0.007181                7  \n",
      "15           0.573248         0.587261        0.013993                3  \n",
      "16           0.588110         0.588960        0.004766                2  \n",
      "17           0.575372         0.566879        0.011783               17  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Definition de la grille pour le  GridSearch\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(100,), (100, 50), (200, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Creation de l'instance MLP\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Creation du GridSearch avec le MLP et les parametres a tester\n",
    "grid_search_mlp = GridSearchCV(mlp, param_grid_mlp)\n",
    "\n",
    "# Entrainement du modele\n",
    "grid_search_mlp.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Recuperation des meilleurs parametres et de l'estimateur\n",
    "best_params_mlp = grid_search_mlp.best_params_\n",
    "best_model_mlp = grid_search_mlp.best_estimator_\n",
    "\n",
    "\n",
    "joblib.dump(best_model_mlp, 'best_model_mlp.pkl')#Souvegarde du modele\n",
    "\n",
    "loaded_model_mlp = joblib.load('best_model_mlp.pkl') #Chargement du modele enregistre\n",
    "\n",
    "# Prediction sur le modele\n",
    "y_pred_mlp = loaded_model_mlp.predict(X_test_sample)\n",
    "\n",
    "# Evaluation des performances du modele\n",
    "print(\"Meilleures parametres MLP:\", best_params_mlp)\n",
    "accuracy_mlp = accuracy_score(y_test_sample, y_pred_mlp)\n",
    "print(\"MLP Accuracy:\", accuracy_mlp)\n",
    "precision = precision_score(y_test_sample, y_pred_mlp, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test_sample, y_pred_mlp, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test_sample, y_pred_mlp, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n",
    "confusion_mat = confusion_matrix(y_test_sample, y_pred_mlp)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n",
    "results = grid_search_mlp.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"Resultats en matrice \\n\",df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.5449915110356537\n",
      "RandomForestClassifier 0.5925297113752123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.5772495755517827\n",
      "VotingClassifier 0.5823429541595926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_1  = joblib.load('best_model_svm.pkl')\n",
    "model_2 = joblib.load('best_model_rf.pkl')\n",
    "model_3 = joblib.load('best_model_mlp.pkl')\n",
    "\n",
    "model_4 = FusionClassifier([('SVM',model_1),\n",
    "     ('RF',model_2),\n",
    "     ('MLP',model_3)],\n",
    "     voting='hard')\n",
    "\n",
    "for model in (model_1,model_2,model_3,model_4):\n",
    "    model.fit(X_train_sample,y_train_sample)\n",
    "    print(model.__class__.__name__,model.score(X_test_sample,y_test_sample))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
