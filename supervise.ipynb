{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Apprentissage Supervis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeur cible 1 :  id_code_insee  -  8258\n",
      "Valeur cible 2 :  Num_Acc  -  40250\n",
      "Valeur cible 3 :  num_veh  -  58\n",
      "Valeur cible 4 :  id_usa  -  73643\n",
      "Valeur cible 5 :  date  -  29950\n",
      "Valeur cible 6 :  ville  -  8078\n",
      "Valeur cible 7 :  latitude.x  -  1253\n",
      "Valeur cible 8 :  longitude.x  -  1495\n",
      "Valeur cible 9 :  descr_cat_veh  -  24\n",
      "Valeur cible 10 :  descr_agglo  -  2\n",
      "Valeur cible 11 :  descr_athmo  -  9\n",
      "Valeur cible 12 :  descr_lum  -  5\n",
      "Valeur cible 13 :  descr_etat_surf  -  9\n",
      "Valeur cible 14 :  description_intersection  -  9\n",
      "Valeur cible 15 :  an_nais  -  101\n",
      "Valeur cible 16 :  age  -  101\n",
      "Valeur cible 17 :  place  -  10\n",
      "Valeur cible 18 :  descr_dispo_secu  -  15\n",
      "Valeur cible 19 :  descr_grav  -  4\n",
      "Valeur cible 20 :  descr_motif_traj  -  6\n",
      "Valeur cible 21 :  descr_type_col  -  7\n",
      "Valeur cible 22 :  department_name  -  89\n",
      "Valeur cible 23 :  department_number  -  89\n",
      "Valeur cible 24 :  region_name  -  17\n",
      "Nombre d'instances :  73643\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des features :  23\n",
      "  id_code_insee       Num_Acc num_veh  id_usa            date  \\\n",
      "0         10100  200900035904     A01  823507  20090803130000   \n",
      "1         10100  200900004313     A01  752937  20090227223000   \n",
      "2         10102  200900005197     A01  754945  20090113160000   \n",
      "3         10102  200900005197     B02  754947  20090113160000   \n",
      "4         10102  200900005206     A01  754970  20090209201500   \n",
      "\n",
      "              ville  latitude.x  longitude.x  descr_cat_veh  descr_agglo  ...  \\\n",
      "0            CLEREY     48.2000          4.2              2            1  ...   \n",
      "1            CLEREY     48.2000          4.2              3            2  ...   \n",
      "2  COLOMBE LA FOSSE     48.2667          4.8              3            2  ...   \n",
      "3  COLOMBE LA FOSSE     48.2667          4.8              3            2  ...   \n",
      "4  COLOMBE LA FOSSE     48.2667          4.8              6            2  ...   \n",
      "\n",
      "   an_nais   age  place                         descr_dispo_secu  descr_grav  \\\n",
      "0   1952.0  57.0    1.0  Utilisation d'une ceinture de s√©curit√©            0   \n",
      "1   1952.0  57.0    1.0  Utilisation d'une ceinture de s√©curit√©            2   \n",
      "2   1969.0  40.0    1.0  Utilisation d'une ceinture de s√©curit√©            2   \n",
      "3   1939.0  70.0    1.0  Utilisation d'une ceinture de s√©curit√©            0   \n",
      "4   1966.0  43.0    1.0                 Utilisation d'un casque            1   \n",
      "\n",
      "   descr_motif_traj                descr_type_col department_name  \\\n",
      "0                 1               Autre collision            aube   \n",
      "1                 9     Deux v√©hicules - Frontale            aube   \n",
      "2                 5  Deux v√©hicules ‚Äì Par le cot√©            aube   \n",
      "3                 5  Deux v√©hicules ‚Äì Par le cot√©            aube   \n",
      "4                 1                Sans collision            aube   \n",
      "\n",
      "   department_number  region_name  \n",
      "0                 10    grand est  \n",
      "1                 10    grand est  \n",
      "2                 10    grand est  \n",
      "3                 10    grand est  \n",
      "4                 10    grand est  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "cc\n"
     ]
    }
   ],
   "source": [
    "%run preparation.ipynb\n",
    "data = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code_insee</th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>id_usa</th>\n",
       "      <th>date</th>\n",
       "      <th>latitude.x</th>\n",
       "      <th>longitude.x</th>\n",
       "      <th>descr_cat_veh</th>\n",
       "      <th>descr_agglo</th>\n",
       "      <th>descr_athmo</th>\n",
       "      <th>descr_lum</th>\n",
       "      <th>...</th>\n",
       "      <th>description_intersection</th>\n",
       "      <th>an_nais</th>\n",
       "      <th>age</th>\n",
       "      <th>place</th>\n",
       "      <th>descr_dispo_secu</th>\n",
       "      <th>descr_grav</th>\n",
       "      <th>descr_motif_traj</th>\n",
       "      <th>descr_type_col</th>\n",
       "      <th>department_number</th>\n",
       "      <th>region_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10100</td>\n",
       "      <td>200900035904</td>\n",
       "      <td>823507</td>\n",
       "      <td>20090803130000</td>\n",
       "      <td>48.2000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10100</td>\n",
       "      <td>200900004313</td>\n",
       "      <td>752937</td>\n",
       "      <td>20090227223000</td>\n",
       "      <td>48.2000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10102</td>\n",
       "      <td>200900005197</td>\n",
       "      <td>754945</td>\n",
       "      <td>20090113160000</td>\n",
       "      <td>48.2667</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10102</td>\n",
       "      <td>200900005197</td>\n",
       "      <td>754947</td>\n",
       "      <td>20090113160000</td>\n",
       "      <td>48.2667</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10102</td>\n",
       "      <td>200900005206</td>\n",
       "      <td>754970</td>\n",
       "      <td>20090209201500</td>\n",
       "      <td>48.2667</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_code_insee       Num_Acc  id_usa            date  latitude.x  \\\n",
       "0          10100  200900035904  823507  20090803130000     48.2000   \n",
       "1          10100  200900004313  752937  20090227223000     48.2000   \n",
       "2          10102  200900005197  754945  20090113160000     48.2667   \n",
       "3          10102  200900005197  754947  20090113160000     48.2667   \n",
       "4          10102  200900005206  754970  20090209201500     48.2667   \n",
       "\n",
       "   longitude.x  descr_cat_veh  descr_agglo  descr_athmo  descr_lum  ...  \\\n",
       "0          4.2              2            1            4          2  ...   \n",
       "1          4.2              3            2            4          3  ...   \n",
       "2          4.8              3            2            5          2  ...   \n",
       "3          4.8              3            2            5          2  ...   \n",
       "4          4.8              6            2            6          1  ...   \n",
       "\n",
       "   description_intersection  an_nais   age  place  descr_dispo_secu  \\\n",
       "0                         1   1952.0  57.0    1.0                 0   \n",
       "1                         1   1952.0  57.0    1.0                 0   \n",
       "2                         2   1969.0  40.0    1.0                 0   \n",
       "3                         2   1939.0  70.0    1.0                 0   \n",
       "4                         4   1966.0  43.0    1.0                 1   \n",
       "\n",
       "   descr_grav  descr_motif_traj  descr_type_col  department_number  \\\n",
       "0           0                 1               0                 10   \n",
       "1           2                 9               1                 10   \n",
       "2           2                 5               2                 10   \n",
       "3           0                 5               2                 10   \n",
       "4           1                 1               3                 10   \n",
       "\n",
       "   region_number  \n",
       "0             44  \n",
       "1             44  \n",
       "2             44  \n",
       "3             44  \n",
       "4             44  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Importation des librairies\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data =pandas.read_csv(\"export_IA.csv\", sep=\",\")\n",
    "\n",
    "#data.info()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 2944 entries, 30308 to 65689\n",
      "Series name: descr_grav\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "2944 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 46.0 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pandas\n",
    "#CREATION D\"UN ECHANTILLOn AFIN DE REALISER DES TESTS DE GRIDSEARCH\n",
    "sample = data\n",
    "#sample.info()\n",
    "count1 = sum(sample['descr_grav'] == 0)\n",
    "count2 = sum(sample['descr_grav'] == 1)\n",
    "count3 = sum(sample['descr_grav'] == 2)\n",
    "count4 = sum(sample['descr_grav'] == 3)\n",
    "#print(count1,count2,count3,count4, count1+count2+count3+count4)\n",
    "\n",
    "#Choix du pourcentage de l'√©chantillon par rapport a la tabe initiale: ici 4% (0.04)\n",
    "sample_size = 0.04\n",
    "sample1 = sample.query('descr_grav == 0').sample(n=int(count1 * sample_size), random_state=25)\n",
    "sample2 = sample.query('descr_grav == 1').sample(n=int(count2 * sample_size), random_state=25)\n",
    "sample3 = sample.query('descr_grav == 2').sample(n=int(count3 * sample_size), random_state=25)\n",
    "sample4 = sample.query('descr_grav == 3').sample(n=int(count4 * sample_size), random_state=25)\n",
    "final_sample = pandas.concat([sample1, sample2, sample3, sample4])\n",
    "#final_sample.info()\n",
    "sample_target = final_sample.pop('descr_grav')\n",
    "sample_target.info()\n",
    "X_train_sample, X_test_sample,y_train_sample, y_test_sample = train_test_split(final_sample,sample_target, test_size=0.2, random_state=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Recuperation de la valeur qui va nous servir de targer: la gravit√© de l'accident\n",
    "target = data.pop(\"descr_grav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Holdout\n",
    "#Repartition des donn√©es en 5 jeux de donn√©es (avec un random_state diff√©rent afin de ne pas orbtenir les memes jeux de donn√©es)\n",
    "X_train1, y_train1, X_test1, y_test1 = train_test_split(data,target, test_size=0.2, random_state=10)\n",
    "X_train2, y_train2, X_test2, y_test2 = train_test_split(data,target, test_size=0.2, random_state=21)\n",
    "X_train3, y_train3, X_test3, y_test3 = train_test_split(data,target, test_size=0.2, random_state=32)\n",
    "X_train4, y_train4, X_test4, y_test4 = train_test_split(data,target, test_size=0.2, random_state=43)\n",
    "X_train5, y_train5, X_test5, y_test5 = train_test_split(data,target, test_size=0.2, random_state=54)\n",
    "\n",
    "\n",
    "#Librairies utiles aux 3 classifications:\n",
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "#RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(data,target, test_size=0.2, random_state=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de donn√©  1\n",
      "Accuracy SVM: 0.4201235657546337\n",
      "Accuracy RF: 0.6330368660465748\n",
      "Accuracy MLP: 0.35338447959807184\n",
      "\n",
      "Jeu de donn√©  2\n",
      "Accuracy SVM: 0.4267092131169801\n",
      "Accuracy RF: 0.6311358544368253\n",
      "Accuracy MLP: 0.028786747233349175\n",
      "\n",
      "Jeu de donn√©  3\n",
      "Accuracy SVM: 0.42209247063615996\n",
      "Accuracy RF: 0.6377893950709485\n",
      "Accuracy MLP: 0.42209247063615996\n",
      "\n",
      "Jeu de donn√©  4\n",
      "Accuracy SVM: 0.42270351008215085\n",
      "Accuracy RF: 0.6322900400570304\n",
      "Accuracy MLP: 0.42270351008215085\n",
      "\n",
      "Jeu de donn√©  5\n",
      "Accuracy SVM: 0.41693258198112565\n",
      "Accuracy RF: 0.6324937198723607\n",
      "Accuracy MLP: 0.41693258198112565\n",
      "\n",
      "Moyenne SVM: 0.4217122683142101\n",
      "Moyenne RF: 0.6333491750967479\n",
      "Moyenne MLP: 0.3287799579061715\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "#Creation de vecteurs afin de stocker les scores de chaque jeu de donn√©es\n",
    "average_SVM = []\n",
    "average_RF = []\n",
    "average_MLP = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(data,target, test_size=0.2, random_state=i*10)\n",
    "    svm.fit(X_train, y_train)\n",
    "    rf.fit(X_train, y_train)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred_svm = svm.predict(X_test)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    y_pred_mlp = mlp.predict(X_test)\n",
    "    print(\"Jeu de donn√© \", i+1)\n",
    "    score_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    score_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    score_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "    print(\"Accuracy SVM:\", score_svm)\n",
    "    average_SVM.append(score_svm)\n",
    "    average_RF.append(score_rf)\n",
    "    average_MLP.append(score_mlp)\n",
    "    print(\"Accuracy RF:\", score_rf)\n",
    "    print(\"Accuracy MLP:\", score_mlp)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "print(\"Moyenne SVM:\", np.mean(average_SVM))\n",
    "print(\"Moyenne RF:\", np.mean(average_RF))\n",
    "print(\"Moyenne MLP:\", np.mean(average_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Leave one out\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(data)\n",
    "for train_index, test_index in loo.split(data):\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de donn√© a partir du Leave One Out :\n",
      "Accuracy SVM: 1.0\n",
      "Accuracy RF: 1.0\n",
      "Accuracy MLP: 1.0\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "mlp = MLPClassifier()\n",
    " \n",
    "svm.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "print(\"Jeu de donn√© a partir du Leave One Out :\")\n",
    "score_svm = accuracy_score(y_test, y_pred_svm)\n",
    "score_rf = accuracy_score(y_test, y_pred_rf)\n",
    "score_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Accuracy SVM:\", score_svm)\n",
    "print(\"Accuracy RF:\", score_rf)\n",
    "print(\"Accuracy MLP:\", score_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From scratch\n",
    "copy_data = dataframe\n",
    "\n",
    "#On melange les donnees de copy_data\n",
    "copy_data = copy_data.sample(frac=1)\n",
    "\n",
    "#On recupere le nombre de lignes de copy_data afin de savoir combien de lignes on va mettre dans le train set et dans le test set pour 80% de train et 20% de test\n",
    "total_rows = len(copy_data)\n",
    "train_size = int(total_rows*0.8)\n",
    "\n",
    "#Separation des donnees entre train et test\n",
    "X_train = copy_data[0:train_size]\n",
    "X_test = copy_data[train_size:]\n",
    "\n",
    "#Separation des donnees entre X et y\n",
    "y_train = X_train.pop('descr_grav')\n",
    "y_test = X_test.pop('descr_grav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de donn√©  1\n",
      "Accuracy SVM: 0.42317876298458823\n",
      "Accuracy RF: 0.6364315296354132\n",
      "Accuracy MLP: 0.3491750967479123\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "mlp = MLPClassifier()\n",
    " \n",
    "svm.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "print(\"Jeu de donn√© from Scratch :\")\n",
    "score_svm = accuracy_score(y_test, y_pred_svm)\n",
    "score_rf = accuracy_score(y_test, y_pred_rf)\n",
    "score_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Accuracy SVM:\", score_svm)\n",
    "print(\"Accuracy RF:\", score_rf)\n",
    "print(\"Accuracy MLP:\", score_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleures parametres SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Meilleur estimateur:  SVC(C=0.1)\n",
      "SVM Accuracy: 0.400679117147708\n",
      "Precision: 0.1605437549182667\n",
      "Recall: 0.400679117147708\n",
      "F1 Score: 0.22923702217420386\n",
      "Matrice de confusion :\n",
      " [[236   0   0   0]\n",
      " [219   0   0   0]\n",
      " [117   0   0   0]\n",
      " [ 17   0   0   0]]\n",
      "Resultat en matrice    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0       0.111112      0.003266         0.074159        0.003571     0.1   \n",
      "1       0.295597      0.009757         0.097740        0.002989     0.1   \n",
      "2       0.111445      0.001431         0.070734        0.000234       1   \n",
      "3       0.306723      0.006238         0.098339        0.001600       1   \n",
      "4       0.108021      0.002179         0.070910        0.000598      10   \n",
      "5       0.258100      0.019796         0.093830        0.003934      10   \n",
      "\n",
      "  param_gamma param_kernel                                         params  \\\n",
      "0       scale          rbf  {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
      "1        auto          rbf   {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}   \n",
      "2       scale          rbf    {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
      "3        auto          rbf     {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}   \n",
      "4       scale          rbf   {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
      "5        auto          rbf    {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}   \n",
      "\n",
      "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0           0.426752           0.424628           0.426752           0.426752   \n",
      "1           0.426752           0.424628           0.426752           0.426752   \n",
      "2           0.426752           0.424628           0.426752           0.426752   \n",
      "3           0.426752           0.424628           0.426752           0.426752   \n",
      "4           0.426752           0.424628           0.426752           0.426752   \n",
      "5           0.426752           0.424628           0.424628           0.426752   \n",
      "\n",
      "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0           0.426752         0.426327        0.000849                1  \n",
      "1           0.426752         0.426327        0.000849                1  \n",
      "2           0.426752         0.426327        0.000849                1  \n",
      "3           0.426752         0.426327        0.000849                1  \n",
      "4           0.426752         0.426327        0.000849                1  \n",
      "5           0.426752         0.425902        0.001040                6  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Definition de la grille pour le  GridSearch\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Creation de l'instance de classification SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Creation du GridSearch avec le SVM et le param_grid\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm)\n",
    "\n",
    "# Entrainement du modele\n",
    "grid_search_svm.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "\n",
    "# Recuperation du meilleur parametre et de l'estimateur\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_model_svm = grid_search_svm.best_estimator_\n",
    "joblib.dump(best_model_svm, 'best_model_svm.pkl')#Souvegarde du modele\n",
    "loaded_model_svm = joblib.load('best_model_svm.pkl') #Chargement du modele enregistre\n",
    "# Prediction sur le modele\n",
    "y_pred_svm = loaded_model_svm.predict(X_test_sample)\n",
    "\n",
    "# Evaluation des performances du modele\n",
    "print(\"Meilleures parametres SVM:\", best_params_svm)\n",
    "print(\"Meilleur estimateur: \", best_model_svm)\n",
    "accuracy_svm = accuracy_score(y_test_sample, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n",
    "precision = precision_score(y_test_sample, y_pred_svm, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test_sample, y_pred_svm, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test_sample, y_pred_svm, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n",
    "confusion_mat = confusion_matrix(y_test_sample, y_pred_svm)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n",
    "results = grid_search_svm.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"Resultat en matrice\",df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleures parametres RF: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Random Forest Accuracy: 0.597623089983022\n",
      "Precision: 0.5739146751062569\n",
      "Recall: 0.597623089983022\n",
      "F1 Score: 0.5782447640605131\n",
      "Matrice de confusion :\n",
      " [[196  31   9   0]\n",
      " [ 68 108  43   0]\n",
      " [ 35  34  48   0]\n",
      " [  7   3   7   0]]\n",
      "Resultats en matric     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.456546      0.016608         0.017405        0.002818   \n",
      "1        0.872436      0.028488         0.029996        0.002085   \n",
      "2        2.705473      0.290115         0.089837        0.011001   \n",
      "3        0.571121      0.057002         0.020839        0.002409   \n",
      "4        1.044180      0.035308         0.034823        0.001912   \n",
      "5        2.617706      0.126886         0.080971        0.004938   \n",
      "6        0.422184      0.016686         0.016325        0.000572   \n",
      "7        0.838272      0.018428         0.029618        0.000375   \n",
      "8        2.073887      0.035535         0.070492        0.001299   \n",
      "9        0.232544      0.003346         0.012504        0.000446   \n",
      "10       0.463199      0.006241         0.023212        0.000394   \n",
      "11       1.150376      0.010580         0.053314        0.000668   \n",
      "12       0.234713      0.004661         0.012605        0.000494   \n",
      "13       0.481561      0.012529         0.023512        0.000883   \n",
      "14       1.163779      0.018960         0.053867        0.000828   \n",
      "15       0.229578      0.002933         0.012414        0.000495   \n",
      "16       0.456145      0.005529         0.022503        0.000646   \n",
      "17       1.163166      0.030832         0.053850        0.000887   \n",
      "18       0.362694      0.003481         0.014831        0.000415   \n",
      "19       0.734451      0.004354         0.027729        0.000399   \n",
      "20       1.828543      0.007001         0.064620        0.001089   \n",
      "21       0.354725      0.002980         0.014941        0.000439   \n",
      "22       0.720127      0.004943         0.027831        0.000506   \n",
      "23       1.817467      0.023126         0.066621        0.002033   \n",
      "24       0.356639      0.006932         0.014605        0.000488   \n",
      "25       0.697101      0.006080         0.027622        0.000807   \n",
      "26       1.733155      0.034095         0.064054        0.001223   \n",
      "\n",
      "   param_max_depth param_min_samples_split param_n_estimators  \\\n",
      "0             None                       2                100   \n",
      "1             None                       2                200   \n",
      "2             None                       2                500   \n",
      "3             None                       5                100   \n",
      "4             None                       5                200   \n",
      "5             None                       5                500   \n",
      "6             None                      10                100   \n",
      "7             None                      10                200   \n",
      "8             None                      10                500   \n",
      "9                5                       2                100   \n",
      "10               5                       2                200   \n",
      "11               5                       2                500   \n",
      "12               5                       5                100   \n",
      "13               5                       5                200   \n",
      "14               5                       5                500   \n",
      "15               5                      10                100   \n",
      "16               5                      10                200   \n",
      "17               5                      10                500   \n",
      "18              10                       2                100   \n",
      "19              10                       2                200   \n",
      "20              10                       2                500   \n",
      "21              10                       5                100   \n",
      "22              10                       5                200   \n",
      "23              10                       5                500   \n",
      "24              10                      10                100   \n",
      "25              10                      10                200   \n",
      "26              10                      10                500   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'max_depth': None, 'min_samples_split': 2, 'n...           0.602972   \n",
      "1   {'max_depth': None, 'min_samples_split': 2, 'n...           0.615711   \n",
      "2   {'max_depth': None, 'min_samples_split': 2, 'n...           0.613588   \n",
      "3   {'max_depth': None, 'min_samples_split': 5, 'n...           0.617834   \n",
      "4   {'max_depth': None, 'min_samples_split': 5, 'n...           0.611465   \n",
      "5   {'max_depth': None, 'min_samples_split': 5, 'n...           0.622081   \n",
      "6   {'max_depth': None, 'min_samples_split': 10, '...           0.622081   \n",
      "7   {'max_depth': None, 'min_samples_split': 10, '...           0.630573   \n",
      "8   {'max_depth': None, 'min_samples_split': 10, '...           0.628450   \n",
      "9   {'max_depth': 5, 'min_samples_split': 2, 'n_es...           0.609342   \n",
      "10  {'max_depth': 5, 'min_samples_split': 2, 'n_es...           0.630573   \n",
      "11  {'max_depth': 5, 'min_samples_split': 2, 'n_es...           0.632696   \n",
      "12  {'max_depth': 5, 'min_samples_split': 5, 'n_es...           0.613588   \n",
      "13  {'max_depth': 5, 'min_samples_split': 5, 'n_es...           0.630573   \n",
      "14  {'max_depth': 5, 'min_samples_split': 5, 'n_es...           0.630573   \n",
      "15  {'max_depth': 5, 'min_samples_split': 10, 'n_e...           0.619958   \n",
      "16  {'max_depth': 5, 'min_samples_split': 10, 'n_e...           0.628450   \n",
      "17  {'max_depth': 5, 'min_samples_split': 10, 'n_e...           0.617834   \n",
      "18  {'max_depth': 10, 'min_samples_split': 2, 'n_e...           0.609342   \n",
      "19  {'max_depth': 10, 'min_samples_split': 2, 'n_e...           0.615711   \n",
      "20  {'max_depth': 10, 'min_samples_split': 2, 'n_e...           0.628450   \n",
      "21  {'max_depth': 10, 'min_samples_split': 5, 'n_e...           0.632696   \n",
      "22  {'max_depth': 10, 'min_samples_split': 5, 'n_e...           0.624204   \n",
      "23  {'max_depth': 10, 'min_samples_split': 5, 'n_e...           0.626327   \n",
      "24  {'max_depth': 10, 'min_samples_split': 10, 'n_...           0.628450   \n",
      "25  {'max_depth': 10, 'min_samples_split': 10, 'n_...           0.641189   \n",
      "26  {'max_depth': 10, 'min_samples_split': 10, 'n_...           0.626327   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.613588           0.598726           0.600849   \n",
      "1            0.617834           0.615711           0.598726   \n",
      "2            0.622081           0.615711           0.598726   \n",
      "3            0.626327           0.624204           0.592357   \n",
      "4            0.626327           0.628450           0.596603   \n",
      "5            0.617834           0.611465           0.583864   \n",
      "6            0.626327           0.636943           0.596603   \n",
      "7            0.636943           0.636943           0.600849   \n",
      "8            0.630573           0.636943           0.596603   \n",
      "9            0.624204           0.622081           0.590234   \n",
      "10           0.630573           0.626327           0.594480   \n",
      "11           0.628450           0.630573           0.590234   \n",
      "12           0.634820           0.630573           0.594480   \n",
      "13           0.628450           0.622081           0.590234   \n",
      "14           0.628450           0.624204           0.585987   \n",
      "15           0.626327           0.619958           0.590234   \n",
      "16           0.632696           0.630573           0.590234   \n",
      "17           0.622081           0.632696           0.592357   \n",
      "18           0.622081           0.632696           0.590234   \n",
      "19           0.624204           0.639066           0.590234   \n",
      "20           0.628450           0.643312           0.583864   \n",
      "21           0.624204           0.632696           0.592357   \n",
      "22           0.615711           0.636943           0.592357   \n",
      "23           0.628450           0.632696           0.592357   \n",
      "24           0.634820           0.639066           0.596603   \n",
      "25           0.634820           0.641189           0.588110   \n",
      "26           0.630573           0.636943           0.583864   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.615711         0.606369        0.006925               27  \n",
      "1            0.624204         0.614437        0.008450               23  \n",
      "2            0.622081         0.614437        0.008556               22  \n",
      "3            0.619958         0.616136        0.012263               19  \n",
      "4            0.613588         0.615287        0.011504               21  \n",
      "5            0.607219         0.608493        0.013334               26  \n",
      "6            0.619958         0.620382        0.013252                9  \n",
      "7            0.632696         0.627601        0.013601                1  \n",
      "8            0.619958         0.622505        0.014045                5  \n",
      "9            0.615711         0.612314        0.012204               25  \n",
      "10           0.609342         0.618259        0.014236               14  \n",
      "11           0.617834         0.619958        0.015717               10  \n",
      "12           0.617834         0.618259        0.014236               14  \n",
      "13           0.615711         0.617410        0.014549               16  \n",
      "14           0.613588         0.616561        0.016369               18  \n",
      "15           0.615711         0.614437        0.012568               23  \n",
      "16           0.613588         0.619108        0.015922               13  \n",
      "17           0.617834         0.616561        0.013266               17  \n",
      "18           0.626327         0.616136        0.015037               19  \n",
      "19           0.639066         0.621656        0.018085                6  \n",
      "20           0.632696         0.623355        0.020479                4  \n",
      "21           0.624204         0.621231        0.014929                7  \n",
      "22           0.628450         0.619533        0.015216               11  \n",
      "23           0.626327         0.621231        0.014624                7  \n",
      "24           0.624204         0.624628        0.014916                3  \n",
      "25           0.619958         0.625053        0.020034                2  \n",
      "26           0.617834         0.619108        0.018684               12  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "#from sklearn.externals import joblib\n",
    "\n",
    "# Define the parameter grid for GridSearch\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create an instance of the Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create a GridSearchCV object with the Random Forest classifier and parameter grid\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf)\n",
    "\n",
    "# Train the model with GridSearch using the training data\n",
    "grid_search_rf.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Get the best parameters and the corresponding Random Forest model\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "joblib.dump(best_model_rf, 'best_model_rf.pkl')#Souvegarde du modele\n",
    "loaded_model_rf = joblib.load('best_model_rf.pkl') #Chargement du modele enregistre\n",
    "# Prediction sur le modele\n",
    "y_pred_rf = loaded_model_rf.predict(X_test_sample)\n",
    "\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(\"Meilleures parametres RF:\", best_params_rf)\n",
    "accuracy_rf = accuracy_score(y_test_sample, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
    "precision = precision_score(y_test_sample, y_pred_rf, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test_sample, y_pred_rf, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test_sample, y_pred_rf, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n",
    "confusion_mat = confusion_matrix(y_test_sample, y_pred_rf)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n",
    "results = grid_search_rf.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"Resultats en matrice\",df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleures parametres MLP: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n",
      "MLP Accuracy: 0.400679117147708\n",
      "Precision: 0.1605437549182667\n",
      "Recall: 0.400679117147708\n",
      "F1 Score: 0.22923702217420386\n",
      "Matrice de confusion :\n",
      " [[236   0   0   0]\n",
      " [219   0   0   0]\n",
      " [117   0   0   0]\n",
      " [ 17   0   0   0]]\n",
      "Resultats en matric     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.146398      0.020085         0.003005        0.000639   \n",
      "1        0.297007      0.084237         0.002598        0.000489   \n",
      "2        0.392892      0.071915         0.002601        0.000490   \n",
      "3        0.184305      0.078447         0.002400        0.000490   \n",
      "4        0.346902      0.165435         0.003018        0.000634   \n",
      "5        0.564986      0.106657         0.002600        0.000801   \n",
      "6        0.154628      0.021720         0.002400        0.000504   \n",
      "7        0.253154      0.054732         0.002601        0.000490   \n",
      "8        0.412330      0.061990         0.003199        0.000979   \n",
      "9        0.292036      0.102817         0.002393        0.000495   \n",
      "10       0.398014      0.075524         0.003399        0.000489   \n",
      "11       0.570291      0.113059         0.003600        0.000490   \n",
      "12       0.376164      0.122380         0.003347        0.000442   \n",
      "13       0.672856      0.218545         0.004837        0.000428   \n",
      "14       0.652841      0.124601         0.005108        0.000657   \n",
      "15       0.297232      0.052041         0.003219        0.000406   \n",
      "16       0.757305      0.224015         0.004200        0.000400   \n",
      "17       0.707049      0.139038         0.005408        0.000486   \n",
      "\n",
      "   param_activation param_alpha param_hidden_layer_sizes  \\\n",
      "0              relu      0.0001                   (100,)   \n",
      "1              relu      0.0001                (100, 50)   \n",
      "2              relu      0.0001               (200, 100)   \n",
      "3              relu       0.001                   (100,)   \n",
      "4              relu       0.001                (100, 50)   \n",
      "5              relu       0.001               (200, 100)   \n",
      "6              relu        0.01                   (100,)   \n",
      "7              relu        0.01                (100, 50)   \n",
      "8              relu        0.01               (200, 100)   \n",
      "9              tanh      0.0001                   (100,)   \n",
      "10             tanh      0.0001                (100, 50)   \n",
      "11             tanh      0.0001               (200, 100)   \n",
      "12             tanh       0.001                   (100,)   \n",
      "13             tanh       0.001                (100, 50)   \n",
      "14             tanh       0.001               (200, 100)   \n",
      "15             tanh        0.01                   (100,)   \n",
      "16             tanh        0.01                (100, 50)   \n",
      "17             tanh        0.01               (200, 100)   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'activation': 'relu', 'alpha': 0.0001, 'hidde...           0.201699   \n",
      "1   {'activation': 'relu', 'alpha': 0.0001, 'hidde...           0.426752   \n",
      "2   {'activation': 'relu', 'alpha': 0.0001, 'hidde...           0.343949   \n",
      "3   {'activation': 'relu', 'alpha': 0.001, 'hidden...           0.343949   \n",
      "4   {'activation': 'relu', 'alpha': 0.001, 'hidden...           0.426752   \n",
      "5   {'activation': 'relu', 'alpha': 0.001, 'hidden...           0.426752   \n",
      "6   {'activation': 'relu', 'alpha': 0.01, 'hidden_...           0.343949   \n",
      "7   {'activation': 'relu', 'alpha': 0.01, 'hidden_...           0.343949   \n",
      "8   {'activation': 'relu', 'alpha': 0.01, 'hidden_...           0.343949   \n",
      "9   {'activation': 'tanh', 'alpha': 0.0001, 'hidde...           0.426752   \n",
      "10  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...           0.426752   \n",
      "11  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...           0.426752   \n",
      "12  {'activation': 'tanh', 'alpha': 0.001, 'hidden...           0.343949   \n",
      "13  {'activation': 'tanh', 'alpha': 0.001, 'hidden...           0.426752   \n",
      "14  {'activation': 'tanh', 'alpha': 0.001, 'hidden...           0.343949   \n",
      "15  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...           0.343949   \n",
      "16  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...           0.426752   \n",
      "17  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...           0.426752   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.343949           0.341826           0.426752   \n",
      "1            0.343949           0.426752           0.341826   \n",
      "2            0.424628           0.341826           0.341826   \n",
      "3            0.424628           0.426752           0.426752   \n",
      "4            0.424628           0.426752           0.426752   \n",
      "5            0.424628           0.426752           0.341826   \n",
      "6            0.203822           0.426752           0.426752   \n",
      "7            0.343949           0.426752           0.426752   \n",
      "8            0.343949           0.426752           0.203822   \n",
      "9            0.424628           0.426752           0.426752   \n",
      "10           0.424628           0.426752           0.341826   \n",
      "11           0.424628           0.426752           0.426752   \n",
      "12           0.424628           0.426752           0.426752   \n",
      "13           0.424628           0.426752           0.426752   \n",
      "14           0.424628           0.426752           0.426752   \n",
      "15           0.424628           0.341826           0.426752   \n",
      "16           0.424628           0.426752           0.426752   \n",
      "17           0.424628           0.426752           0.426752   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.426752         0.348195        0.082295               16  \n",
      "1            0.341826         0.376221        0.041265               13  \n",
      "2            0.201699         0.330786        0.071954               17  \n",
      "3            0.201699         0.364756        0.087513               15  \n",
      "4            0.201699         0.381316        0.089813               12  \n",
      "5            0.426752         0.409342        0.033768                7  \n",
      "6            0.426752         0.365605        0.087017               14  \n",
      "7            0.426752         0.393631        0.040565                9  \n",
      "8            0.201699         0.304034        0.088047               18  \n",
      "9            0.426752         0.426327        0.000849                1  \n",
      "10           0.426752         0.409342        0.033768                7  \n",
      "11           0.426752         0.426327        0.000849                1  \n",
      "12           0.426752         0.409766        0.032919                6  \n",
      "13           0.426752         0.426327        0.000849                1  \n",
      "14           0.341826         0.392781        0.040751               10  \n",
      "15           0.426752         0.392781        0.040751               10  \n",
      "16           0.426752         0.426327        0.000849                1  \n",
      "17           0.426752         0.426327        0.000849                1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antonin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Define the parameter grid for GridSearch\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(100,), (100, 50), (200, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Create an instance of the MLP classifier\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Create a GridSearchCV object with the MLP classifier and parameter grid\n",
    "grid_search_mlp = GridSearchCV(mlp, param_grid_mlp)\n",
    "\n",
    "# Train the model with GridSearch using the training data\n",
    "grid_search_mlp.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Get the best parameters and the corresponding MLP model\n",
    "best_params_mlp = grid_search_mlp.best_params_\n",
    "best_model_mlp = grid_search_mlp.best_estimator_\n",
    "\n",
    "\n",
    "# Save the best model using joblib\n",
    "joblib.dump(best_model_mlp, 'best_model_mlp.pkl')\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model_mlp = joblib.load('best_model_mlp.pkl')\n",
    "\n",
    "# Make predictions on the test data using the loaded model\n",
    "y_pred_mlp = loaded_model_mlp.predict(X_test_sample)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(\"Meilleures parametres MLP:\", best_params_mlp)\n",
    "accuracy_mlp = accuracy_score(y_test_sample, y_pred_mlp)\n",
    "print(\"MLP Accuracy:\", accuracy_mlp)\n",
    "precision = precision_score(y_test_sample, y_pred_mlp, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test_sample, y_pred_mlp, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test_sample, y_pred_mlp, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n",
    "confusion_mat = confusion_matrix(y_test_sample, y_pred_mlp)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n",
    "results = grid_search_mlp.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"Resultats en matrice\",df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.42419716206123975\n",
      "RandomForestClassifier 0.6317468938828162\n",
      "MLPClassifier 0.42419716206123975\n",
      "VotingClassifier 0.42419716206123975\n"
     ]
    }
   ],
   "source": [
    "model_1  = joblib.load('best_model_svm.pkl')\n",
    "model_2 = joblib.load('best_model_rf.pkl')\n",
    "model_3 = joblib.load('best_model_mlp.pkl')\n",
    "\n",
    "model_4 = VotingClassifier([('SGD',model_1),\n",
    "     ('Tree',model_2),\n",
    "     ('KNN',model_3)],\n",
    "     voting='hard')\n",
    "\n",
    "for model in (model_1,model_2,model_3,model_4):\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.__class__.__name__,model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Fusion Majoritaire des predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fusion_predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39margmax(np\u001b[39m.\u001b[39mbincount([y_pred_svm, y_pred_rf, y_pred_mlp])) \u001b[39mfor\u001b[39;00m y_pred_rf, y_pred_svm, y_pred_mlp \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(rf_predictions, svm_predictions, mlp_predictions)])\n\u001b[0;32m      4\u001b[0m \u001b[39m# Calculate accuracy of fusion predictions\u001b[39;00m\n\u001b[0;32m      5\u001b[0m fusion_accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, fusion_predictions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "#Fusion Majoritaire des predictions\n",
    "fusion_predictions = np.array([np.argmax(np.bincount([y_pred_svm, y_pred_rf, y_pred_mlp])) for y_pred_rf, y_pred_svm, y_pred_mlp in zip(rf_predictions, svm_predictions, mlp_predictions)])\n",
    "\n",
    "# Calculate accuracy of fusion predictions\n",
    "fusion_accuracy = accuracy_score(y_test, fusion_predictions)\n",
    "\n",
    "print(\"Accuracy of fusion predictions:\", fusion_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Perform majority voting fusion\n",
    "fusion_predictions = np.array([np.argmax(np.bincount([y_pred_rf, y_pred_svm, y_pred_mlp])) for y_pred_rf, y_pred_svm, mlp_pred in zip(rf_predictions, svm_predictions, mlp_predictions)])\n",
    "\n",
    "# Calculate accuracy of fusion predictions\n",
    "fusion_accuracy = accuracy_score(y_test, fusion_predictions)\n",
    "\n",
    "print(\"Accuracy of fusion predictions:\", fusion_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
